import argparse
import ujson as json
from pysaurus.core.components import AbsolutePath, FileSize, FilePath
import math
from pysaurus.core.profiling import Profiler
import os


def main():
    parser = argparse.ArgumentParser(description="Move duplicates into separate folders")
    parser.add_argument("-i", "--input", required=True, help="Input JSON file listing duplicates, generated by `find_duplicate_files`")
    parser.add_argument("-o", "--output", required=True, help="Output folder to generate duplicate sub-folders.")
    args = parser.parse_args()
    output_folder = AbsolutePath(args.output)
    if not output_folder.exists():
        print('Create output folder', output_folder)
        output_folder.mkdir()
    if not output_folder.isdir():
        print('No folder found at output path', output_folder)
        exit(-1)
    with open(args.input) as file:
        duplicates = json.load(file)
    duplicates = [[size, [AbsolutePath(f) for f in files]] for size, files in duplicates]
    duplicates.sort()
    nb_files = 0
    total_size = 0
    max_size = 0
    for size, files in duplicates:
        nb_files += len(files)
        total_size += size * len(files)
        max_size = max(max_size, size)
    print('Loaded', len(duplicates), 'duplicate(s) for', nb_files, 'file(s) with total size', FileSize(total_size), 'from', duplicates[0][0], 'to', duplicates[-1][0])
    len_size_string = int(math.log10(max_size)) + 1
    movements = []
    folders = []
    with Profiler("Generate move args"):
        for i, (size, files) in enumerate(duplicates[:4]):
            files = [f for f in files if f.exists()]
            if len(files) < 2:
                continue
            dup_folder_path = AbsolutePath.join(output_folder, str(size).rjust(len_size_string, "0"))
            folders.append(dup_folder_path)
            len_title_writing = int(math.log10(len(files))) + 1
            for file_no, file_path in enumerate(sorted(files, key=lambda f: (len(f.title), f.title.lower(), f.title))):
                output_file_path = FilePath(dup_folder_path, f"dup{str(file_no).rjust(len_title_writing,'0')}_{file_path.title}", file_path.extension)
                movements.append((file_path, output_file_path))
            if (i + 1) % 100 == 0:
                print('Handled', i + 1, 'duplicate(s)')
    with Profiler("Create duplicate folders"):
        for folder in folders:
            if not folder.exists():
                folder.mkdir()
            if not folder.isdir():
                raise RuntimeError(f"Unable to create or locate folder {folder}")
    with Profiler("Move duplicate files"):
        for i, (inp, out) in enumerate(movements):
            os.rename(inp.path, out.path)
            assert not inp.exists()
            assert out.isfile()
            if (i + 1) % 100 == 0:
                print("Moved", i + 1)


if __name__ == '__main__':
    main()
